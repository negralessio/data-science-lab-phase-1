{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a217fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway, chi2_contingency, pointbiserialr\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341ced2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e687130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "dir_data = '../../data/raw/'\n",
    "\n",
    "# File names\n",
    "filename_train_features = 'train_values.csv'\n",
    "\n",
    "# Create paths for given files\n",
    "filepath_train_features = os.path.join(dir_data, filename_train_features)\n",
    "\n",
    "# Check if files and data folder exist\n",
    "if not os.path.isdir(dir_data):\n",
    "    raise FileNotFoundError(\"Data directory is missing\")\n",
    "if not len(os.listdir(dir_data)):\n",
    "    raise FileNotFoundError(\"Files missing\")\n",
    "\n",
    "if not filepath_train_features:\n",
    "    raise FileNotFoundError(f\"{filename_train_features} is missing.\")\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(filepath_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5078961",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29332e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists of features according to their datatype in the documentation\n",
    "int_features = [\"geo_level_1_id\", \"geo_level_2_id\", \"geo_level_3_id\", \"count_floors_pre_eq\", \"age\", \"area_percentage\", \"height_percentage\", \"count_families\"]\n",
    "cat_features = [\"land_surface_condition\", \"foundation_type\", \"roof_type\", \"ground_floor_type\", \"other_floor_type\", \"position\", \"plan_configuration\", \"legal_ownership_status\"]\n",
    "bin_features = [\"has_superstructure_adobe_mud\", \"has_superstructure_mud_mortar_stone\", \"has_superstructure_stone_flag\", \"has_superstructure_cement_mortar_stone\", \"has_superstructure_mud_mortar_brick\", \"has_superstructure_cement_mortar_brick\", \"has_superstructure_timber\", \"has_superstructure_bamboo\", \"has_superstructure_rc_non_engineered\", \"has_superstructure_rc_engineered\", \"has_superstructure_other\", \"has_secondary_use\", \"has_secondary_use_agriculture\", \"has_secondary_use_hotel\", \"has_secondary_use_rental\", \"has_secondary_use_institution\", \"has_secondary_use_school\", \"has_secondary_use_industry\", \"has_secondary_use_health_post\", \"has_secondary_use_gov_office\", \"has_secondary_use_use_police\", \"has_secondary_use_other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b41717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pearson_correlated_features(data=None, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Calculates the pearson correlation of all features in the dataframe and returns a set of features with a correlation greater than the threshold. \n",
    "    \n",
    "    :param data: Dataframe with features and values\n",
    "    :param threshold: A number between 0 and 1\n",
    "    \n",
    "    :returns A set of correlated feature names\n",
    "    \"\"\"\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = data.corr()\n",
    "\n",
    "    # Get the set of correlated features\n",
    "    correlated_features = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "    \n",
    "    return correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1056f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cramers_v_correlated_features(data=None, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Calculates the cramers V correlation of all features and returns a set of features with a correlation greater than the threshold. \n",
    "    Cramers V is based on Chi square, for reference see: https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\n",
    "    Note that this function is desined to work for categorical features only!\n",
    "    Code was copied and modified from this source: https://www.kaggle.com/code/chrisbss1/cramer-s-v-correlation-matrix/notebook\n",
    "    \n",
    "    :param data: Dataframe with features and values\n",
    "    :param threshold: A number between 0 and 1\n",
    "    \n",
    "    :returns A set of correlated feature names\n",
    "    \"\"\"\n",
    "    # Encode features\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    data_encoded = pd.DataFrame() \n",
    "\n",
    "    for i in data.columns :\n",
    "        data_encoded[i]=label.fit_transform(data[i])\n",
    "\n",
    "    # Internal function to calculate cramers V for two features\n",
    "    def _cramers_V(var1, var2) :\n",
    "        crosstab = np.array(pd.crosstab(var1,var2, rownames=None, colnames=None))  # Cross table building\n",
    "        stat = chi2_contingency(crosstab)[0]  # Keeping of the test statistic of the Chi2 test\n",
    "        obs = np.sum(crosstab)  # Number of observations\n",
    "        mini = min(crosstab.shape) - 1  # Take the minimum value between the columns and the rows of the cross table\n",
    "        return (stat / (obs * mini))\n",
    "        #return stat\n",
    "\n",
    "    # Calculate values for each pair of features\n",
    "    rows= []\n",
    "    for var1 in data_encoded:\n",
    "        col = []\n",
    "        for var2 in data_encoded :\n",
    "            cramers = _cramers_V(data_encoded[var1], data_encoded[var2])  # Cramer's V test\n",
    "            col.append(round(cramers, 4))  # Keeping of the rounded value of the Cramer's V  \n",
    "        rows.append(col)\n",
    "    \n",
    "    # Create a pandas df from the results\n",
    "    cramers_results = np.array(rows)\n",
    "    corr_matrix = pd.DataFrame(cramers_results, columns = data_encoded.columns, index =data_encoded.columns)\n",
    "    \n",
    "    # Get the set of correlated features\n",
    "    correlated_features = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "    \n",
    "    return correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53ff1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mcc_correlated_features(data=None, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Calculates the MCC correlation of all features and returns a set of features with a correlation greater than the threshold. \n",
    "    Cramers V is based on Chi square, for reference see: https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\n",
    "    Note that this function is desined to work for categorical features only!\n",
    "    Code was copied and modified from this source: https://www.kaggle.com/code/chrisbss1/cramer-s-v-correlation-matrix/notebook\n",
    "    \n",
    "    :param data: Dataframe with features and values\n",
    "    :param threshold: A number between 0 and 1\n",
    "    \n",
    "    :returns A set of correlated feature names\n",
    "    \"\"\"\n",
    "    # Encode features\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    data_encoded = pd.DataFrame() \n",
    "\n",
    "    label = preprocessing.LabelEncoder()\n",
    "    data_encoded = pd.DataFrame() \n",
    "\n",
    "    for c in data.columns:\n",
    "        if c in cat_features:\n",
    "            data_encoded[c] = label.fit_transform(data[c])\n",
    "        else:\n",
    "            data_encoded[c] = data[c]\n",
    "    \n",
    "    # Calculate values for each pair of features\n",
    "    rows= []\n",
    "    for var1 in data_encoded:\n",
    "        col = []\n",
    "        for var2 in data_encoded :\n",
    "            phi = matthews_corrcoef(data_encoded[var1], data_encoded[var2])  \n",
    "            col.append(phi)  # phi  \n",
    "        rows.append(col)\n",
    "    \n",
    "    # Create a pandas df from the results\n",
    "    phi_results = np.array(rows)\n",
    "    corr_matrix = pd.DataFrame(phi_results, columns=data_encoded.columns, index=data_encoded.columns)\n",
    "    \n",
    "    # Get the set of correlated features\n",
    "    correlated_features = set()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "    \n",
    "    return correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bac91d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_correlated_features(data=None, config=None):\n",
    "    \"\"\"\n",
    "    Gets the correlated features according to the configuration and drops them from the provided dataframe. \n",
    "    Then the dataframe without the correlated features is returned. \n",
    "    \n",
    "    Example for the config: \n",
    "    [\n",
    "        {\n",
    "            'feature_names': <List of feature names>,\n",
    "            'threshold'    : A number between 0 and 1\n",
    "            'method'       : <One out of the set {'MCC', 'CramesV', 'Pearson'}>\n",
    "        },\n",
    "        {\n",
    "            'feature_names': <List of feature names>,\n",
    "            'threshold'    : A number between 0 and 1\n",
    "            'method'       : <One out of the set {'MCC', 'CramesV', 'Pearson'}>\n",
    "        }, ...\n",
    "    ]\n",
    "    \n",
    "    :param data: The dataframe to drop the features from\n",
    "    :param config: A list of dicts. Every dict has to contain the keys 'feature_names', 'method' and 'threshold'. \n",
    "                   The 'feature_names' determine of which features the correlation is calculated. \n",
    "                   Method has to be one out of the set {'MCC', 'CramesV', 'Pearson'}.\n",
    "                   The value of method determines the function which is used to calculate the correlations.\n",
    "                   Only features with a higher correlation than 'threshold' will be dropped. \n",
    "                   \n",
    "    :returns A dataframe without the correlated features\n",
    "    \"\"\"\n",
    "    # Traverse all dicts in the config\n",
    "    # Note: This could be parallelized\n",
    "    for d in config:\n",
    "        if d['method'] == 'MCC':\n",
    "            features_to_drop = get_mcc_correlated_features(data=data[d['feature_names']], threshold=d['threshold'])\n",
    "        elif d['method'] == 'CramersV':\n",
    "            features_to_drop = get_cramers_v_correlated_features(data=data[d['feature_names']], threshold=d['threshold'])\n",
    "        elif d['method'] == 'Pearson':\n",
    "            features_to_drop = get_pearson_correlated_features(data=data[d['feature_names']], threshold=d['threshold'])\n",
    "        else: \n",
    "            print(f\"Correlation method '{d['method']}' is not implemented.\")\n",
    "        \n",
    "        # Drop features\n",
    "        if len(features_to_drop) > 0:\n",
    "            data = data.drop(features_to_drop, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61a839",
   "metadata": {},
   "source": [
    "# Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03fa750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'height_percentage'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pearson_correlated_features(data=data[int_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b05ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cramers_v_correlated_features(data=data[cat_features + bin_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83affaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'has_secondary_use_agriculture', 'has_secondary_use_hotel'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mcc_correlated_features(data=data[cat_features + bin_features], threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84dca94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260601, 39)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c1a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    {\n",
    "        'feature_names': int_features,\n",
    "        'threshold'    : 0.7,\n",
    "        'method'       : 'Pearson'\n",
    "    },\n",
    "    {\n",
    "        'feature_names': cat_features + bin_features,\n",
    "        'threshold'    : 0.7,\n",
    "        'method'       : 'MCC'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = drop_correlated_features(data=data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1debf7be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
